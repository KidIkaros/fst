{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Full Token Sonar Training (Production Grade)\n",
        "\n",
        "This notebook implements a robust training pipeline for the **Full Token Sonar** student model. It is designed for \"set it and forget it\" execution on platforms like Kaggle or Colab, with features for checkpointing, easy resuming, and validation monitoring.\n",
        "\n",
        "### Features:\n",
        "- **Architecture**: 6-layer Transformer Encoder (Student) vs 24-layer SONAR (Teacher).\n",
        "- **Robustness**: Automated Checkpointing (Best & Last), Early Stopping.\n",
        "- **Optimization**: Mixed Precision (AMP), Multi-GPU DataParallel.\n",
        "- **Resume Capability**: Automatically detects and loads the best previous checkpoint.\n",
        "- **Verification**: Integrated Unit Tests to ensure model integrity before training.\n",
        "- **Integration**: GitHub synchronization for code updates."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title 1. Environment Setup & Dependencies\n",
        "import os\n",
        "import sys\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "\n",
        "# Detect Environment\n",
        "IS_KAGGLE = os.environ.get('KAGGLE_KERNEL_RUN_TYPE', '') != ''\n",
        "IS_COLAB = 'google.colab' in sys.modules\n",
        "\n",
        "print(f\"Environment: {'Kaggle' if IS_KAGGLE else 'Colab' if IS_COLAB else 'Local'}\")\n",
        "\n",
        "# AGGRESSIVE CLEANUP\n",
        "# We must uninstall numpy and pandas first to remove any system-level mismatched binaries.\n",
        "print(\"Cleaning up environment (Uninstalling existing numpy/pandas)...\")\n",
        "%pip uninstall -y numpy pandas\n",
        "\n",
        "# FRESH INSTALL\n",
        "# Pin numpy==1.26.4 explicitly to ensure maximum compatibility.\n",
        "print(\"Installing dependencies...\")\n",
        "%pip install -U --force-reinstall \"numpy==1.26.4\" \"pandas<2.2.0\" datasets sonar-space fairseq2 onnxruntime-gpu\n",
        "\n",
        "# Verify Imports Immediately\n",
        "print(\"Verifying installations...\")\n",
        "try:\n",
        "    import numpy\n",
        "    print(f\"\u2713 Numpy Version: {numpy.__version__}\")\n",
        "    import pandas\n",
        "    print(f\"\u2713 Pandas Version: {pandas.__version__}\")\n",
        "    import sonar\n",
        "    from sonar.inference_pipelines.text import TextToEmbeddingModelPipeline\n",
        "    print(f\"\u2713 SONAR installed successfully\")\n",
        "except (ImportError, ValueError) as e:\n",
        "    print(f\"\u274c CRITICAL INSTALLATION ERROR: {e}\")\n",
        "    print(\"\\n!!! PLEASE RESTART THE KERNEL AND RUN THIS CELL AGAIN !!!\")\n",
        "    print(\"In Colab: Runtime > Restart Session\")\n",
        "    print(\"In Kaggle: Run > Restart Kernel\")\n",
        "    raise e\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title 2. Git & Checkpoint Management\n",
        "# Setup paths to persist data across sessions\n",
        "\n",
        "if IS_KAGGLE:\n",
        "    # Kaggle specific paths\n",
        "    WORK_DIR = Path(\"/kaggle/working\")\n",
        "    CHECKPOINT_DIR = Path(\"/kaggle/working/checkpoints\")\n",
        "    # Try to load input dataset if available (pseudo-code path)\n",
        "    INPUT_DIR = Path(\"/kaggle/input/fst-checkpoints\")\n",
        "elif IS_COLAB:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    WORK_DIR = Path(\"/content/fst\")\n",
        "    CHECKPOINT_DIR = Path(\"/content/drive/MyDrive/FST_Checkpoints\")\n",
        "else:\n",
        "    # Local\n",
        "    WORK_DIR = Path(os.getcwd())\n",
        "    CHECKPOINT_DIR = WORK_DIR / \"checkpoints\"\n",
        "\n",
        "CHECKPOINT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "print(f\"Checkpoints will be saved to: {CHECKPOINT_DIR}\")\n",
        "\n",
        "# GitHub Sync (Optional - for code updates)\n",
        "REPO_URL = \"https://github.com/KidIkaros/fst.git\"\n",
        "if not (WORK_DIR / \".git\").exists() and (IS_KAGGLE or IS_COLAB):\n",
        "    print(\"Cloning repository...\")\n",
        "    !git clone $REPO_URL $WORK_DIR\n",
        "else:\n",
        "    print(\"Repository already present or local mode.\")\n",
        "    # If we are in the repo but want to pull latest changes (e.g. after a fix)\n",
        "    if (WORK_DIR / \".git\").exists() and (IS_KAGGLE or IS_COLAB):\n",
        "        print(\"Pulling latest changes...\")\n",
        "        !cd $WORK_DIR && git pull\n",
        "\n",
        "# Reconstruct Checkpoint from Split Parts (if needed)\n",
        "def reconstruct_checkpoint():\n",
        "    # Check if we have parts but no main file\n",
        "    parts = sorted([str(p) for p in (WORK_DIR / \"checkpoints\").glob(\"full_token_sonar_best_part_*\")])\n",
        "    if not parts:\n",
        "         # Check directly in current dir just in case\n",
        "         parts = sorted([str(p) for p in (WORK_DIR).glob(\"checkpoints/full_token_sonar_best_part_*\")])\n",
        "\n",
        "    target = CHECKPOINT_DIR / \"full_token_sonar_best.pt\"\n",
        "    \n",
        "    if parts and not target.exists():\n",
        "        print(f\"Found {len(parts)} checkpoint parts. Reconstructing to {target}...\")\n",
        "        try:\n",
        "            with open(target, \"wb\") as outfile:\n",
        "                for part in parts:\n",
        "                    print(f\"Mergin {part}...\")\n",
        "                    with open(part, \"rb\") as infile:\n",
        "                        outfile.write(infile.read())\n",
        "            print(\"Reconstruction complete.\")\n",
        "        except Exception as e:\n",
        "            print(f\"Reconstruction failed: {e}\")\n",
        "    elif target.exists():\n",
        "        print(\"Checkpoint file already exists.\")\n",
        "    else:\n",
        "        print(\"No checkpoint parts found to reconstruct.\")\n",
        "\n",
        "reconstruct_checkpoint()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title 3. Model Definition\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "\n",
        "class SinusoidalPositionEncoder(nn.Module):\n",
        "    \"\"\"Sinusoidal positional encoding\"\"\"\n",
        "    def __init__(self, encoding_dim, max_seq_len=514):\n",
        "        super().__init__()\n",
        "        self.encoding_dim = encoding_dim\n",
        "        position = torch.arange(max_seq_len).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, encoding_dim, 2) * (-math.log(10000.0) / encoding_dim))\n",
        "        pe = torch.zeros(max_seq_len, encoding_dim)\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        self.register_buffer('pe', pe.unsqueeze(0))\n",
        "    \n",
        "    def forward(self, x):\n",
        "        return x + self.pe[:, :x.size(1)]\n",
        "\n",
        "class FullTokenSonar(nn.Module):\n",
        "    def __init__(self, vocab_size=256206, embed_dim=512, layers=6, num_heads=8, output_dim=1024, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.embed = nn.Embedding(vocab_size, embed_dim, padding_idx=1)\n",
        "        self.pos_encoder = SinusoidalPositionEncoder(embed_dim, max_seq_len=514)\n",
        "        \n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=embed_dim,\n",
        "            nhead=num_heads,\n",
        "            dim_feedforward=embed_dim * 4,\n",
        "            batch_first=True,\n",
        "            activation=\"gelu\",\n",
        "            norm_first=True,\n",
        "            dropout=dropout\n",
        "        )\n",
        "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=layers)\n",
        "        \n",
        "        self.attention_pool = nn.Sequential(\n",
        "            nn.Linear(embed_dim, 128),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(128, 1)\n",
        "        )\n",
        "        \n",
        "        self.projection = nn.Sequential(\n",
        "            nn.LayerNorm(embed_dim),\n",
        "            nn.Linear(embed_dim, output_dim),\n",
        "            nn.LayerNorm(output_dim)\n",
        "        )\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        x = self.embed(input_ids)\n",
        "        x = self.pos_encoder(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.encoder(x, src_key_padding_mask=attention_mask)\n",
        "        \n",
        "        attn_scores = self.attention_pool(x).squeeze(-1)\n",
        "        mask_float = attention_mask.float() * -1e9\n",
        "        attn_scores = attn_scores + mask_float\n",
        "        attn_weights = F.softmax(attn_scores, dim=-1).unsqueeze(-1)\n",
        "        \n",
        "        x_pooled = torch.sum(x * attn_weights, dim=1)\n",
        "        x = self.projection(x_pooled)\n",
        "        return F.normalize(x, p=2, dim=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title 4. Unit Tests\n",
        "import unittest\n",
        "\n",
        "class TestFullTokenSonar(unittest.TestCase):\n",
        "    def setUp(self):\n",
        "        self.model = FullTokenSonar(vocab_size=100, embed_dim=32, layers=2, num_heads=4, output_dim=64)\n",
        "        self.model.eval()\n",
        "\n",
        "    def test_output_shape(self):\n",
        "        batch_size = 2\n",
        "        seq_len = 10\n",
        "        input_ids = torch.randint(0, 100, (batch_size, seq_len))\n",
        "        mask = torch.zeros((batch_size, seq_len), dtype=torch.bool)\n",
        "        \n",
        "        output = self.model(input_ids, mask)\n",
        "        self.assertEqual(output.shape, (batch_size, 64))\n",
        "        \n",
        "    def test_masking_effect(self):\n",
        "        # Ensure that masking actually ignores padded tokens\n",
        "        input_ids = torch.randint(0, 100, (1, 10))\n",
        "        mask1 = torch.zeros((1, 10), dtype=torch.bool)\n",
        "        mask2 = torch.zeros((1, 10), dtype=torch.bool)\n",
        "        mask2[0, 5:] = True # Mask last 5 tokens\n",
        "        \n",
        "        # We expect different outputs since pooling should ignore masked tokens\n",
        "        out1 = self.model(input_ids, mask1)\n",
        "        out2 = self.model(input_ids, mask2)\n",
        "        \n",
        "        self.assertFalse(torch.allclose(out1, out2), \"Masking did not affect output\")\n",
        "\n",
        "def run_tests():\n",
        "    suite = unittest.TestLoader().loadTestsFromTestCase(TestFullTokenSonar)\n",
        "    unittest.TextTestRunner(verbosity=2).run(suite)\n",
        "\n",
        "run_tests()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title 5. Training Infrastructure (The Engine)\n",
        "import random\n",
        "from datasets import load_dataset\n",
        "from sonar.inference_pipelines.text import TextToEmbeddingModelPipeline\n",
        "\n",
        "class Trainer:\n",
        "    def __init__(self, student, teacher, device, learning_rate=2e-4):\n",
        "        self.student = student\n",
        "        self.teacher = teacher\n",
        "        self.device = device\n",
        "        \n",
        "        # Check for multi-GPU\n",
        "        if torch.cuda.device_count() > 1:\n",
        "            print(f\"Trainer: Wrapping model in DataParallel ({torch.cuda.device_count()} GPUs)\")\n",
        "            self.student_parallel = nn.DataParallel(student)\n",
        "        else:\n",
        "            self.student_parallel = student\n",
        "            \n",
        "        self.optimizer = torch.optim.AdamW(\n",
        "            student.parameters(), lr=learning_rate, weight_decay=0.01, betas=(0.9, 0.999)\n",
        "        )\n",
        "        self.scaler = torch.amp.GradScaler('cuda')\n",
        "        self.best_loss = float('inf')\n",
        "        self.patience_counter = 0\n",
        "        \n",
        "    def save_checkpoint(self, path, epoch, loss):\n",
        "        # Handle DataParallel unwrapping\n",
        "        model_state = self.student_parallel.module.state_dict() if isinstance(self.student_parallel, nn.DataParallel) else self.student_parallel.state_dict()\n",
        "        \n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model_state,\n",
        "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
        "            'loss': loss,\n",
        "        }, path)\n",
        "        \n",
        "    def load_checkpoint(self, path):\n",
        "        if not os.path.exists(path):\n",
        "            print(f\"No checkpoint found at {path}\")\n",
        "            return 0\n",
        "            \n",
        "        print(f\"Loading checkpoint from {path}...\")\n",
        "        checkpoint = torch.load(path, map_location=self.device)\n",
        "        \n",
        "        # Handle keys if model was saved as DataParallel but loading to single or vice versa\n",
        "        # (Ideally we save unwrapped, which we do above)\n",
        "        self.student.load_state_dict(checkpoint['model_state_dict'])\n",
        "        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "        return checkpoint.get('epoch', 0)\n",
        "\n",
        "    def train_epoch(self, texts, batch_size=16, step_callback=None):\n",
        "        self.student_parallel.train()\n",
        "        total_loss = 0\n",
        "        steps = len(texts) // batch_size\n",
        "        \n",
        "        random.shuffle(texts)\n",
        "        \n",
        "        for i in range(steps):\n",
        "            batch_texts = texts[i*batch_size : (i+1)*batch_size]\n",
        "            \n",
        "            # Batch Preparation (CPU)\n",
        "            batch_tokens = []\n",
        "            max_len = 0\n",
        "            for text in batch_texts:\n",
        "                try:\n",
        "                    enc = self.teacher.tokenizer.create_encoder()(text)\n",
        "                    if len(enc) < 512: \n",
        "                        batch_tokens.append(enc)\n",
        "                        max_len = max(max_len, len(enc))\n",
        "                except: continue\n",
        "            \n",
        "            if len(batch_tokens) < 1: continue\n",
        "            \n",
        "            # Padding\n",
        "            input_ids = torch.zeros((len(batch_tokens), max_len), dtype=torch.long)\n",
        "            mask = torch.ones((len(batch_tokens), max_len), dtype=torch.bool)\n",
        "            \n",
        "            for j, tok in enumerate(batch_tokens):\n",
        "                input_ids[j, :len(tok)] = tok\n",
        "                mask[j, :len(tok)] = False\n",
        "                \n",
        "            input_ids = input_ids.to(self.device)\n",
        "            mask = mask.to(self.device)\n",
        "            \n",
        "            try:\n",
        "                # Teacher Logic\n",
        "                with torch.no_grad():\n",
        "                    t_vecs = self.teacher.predict(batch_texts, source_lang=\"eng_Latn\")\n",
        "                    t_vecs = F.normalize(t_vecs, p=2, dim=-1)\n",
        "\n",
        "                # Student Logic\n",
        "                with torch.amp.autocast('cuda'):\n",
        "                    s_vecs = self.student_parallel(input_ids, mask)\n",
        "                    loss = 1.0 - F.cosine_similarity(s_vecs, t_vecs).mean()\n",
        "                \n",
        "                self.optimizer.zero_grad()\n",
        "                self.scaler.scale(loss).backward()\n",
        "                self.scaler.unscale_(self.optimizer)\n",
        "                torch.nn.utils.clip_grad_norm_(self.student_parallel.parameters(), 1.0)\n",
        "                self.scaler.step(self.optimizer)\n",
        "                self.scaler.update()\n",
        "                \n",
        "                total_loss += loss.item()\n",
        "                if step_callback: step_callback(i, loss.item())\n",
        "                \n",
        "            except RuntimeError as e:\n",
        "                if \"out of memory\" in str(e):\n",
        "                    torch.cuda.empty_cache()\n",
        "                else:\n",
        "                    print(f\"Error: {e}\")\n",
        "        \n",
        "        return total_loss / steps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title 6. Execution\n",
        "\n",
        "# 1. Setup\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Initializing SONAR Teacher... (this takes a moment)\")\n",
        "teacher = TextToEmbeddingModelPipeline(\n",
        "    encoder=\"text_sonar_basic_encoder\", \n",
        "    tokenizer=\"text_sonar_basic_encoder\", \n",
        "    device=device,\n",
        "    dtype=torch.float32\n",
        ")\n",
        "\n",
        "student = FullTokenSonar().to(device)\n",
        "trainer = Trainer(student, teacher, device)\n",
        "\n",
        "# 2. Smart Resume\n",
        "resume_path = CHECKPOINT_DIR / \"full_token_sonar_best.pt\"\n",
        "start_epoch = 0\n",
        "\n",
        "if resume_path.exists():\n",
        "    print(\"Found existing checkpoint. Resuming...\")\n",
        "    start_epoch = trainer.load_checkpoint(str(resume_path))\n",
        "    print(f\"Resuming from Epoch {start_epoch}\")\n",
        "else:\n",
        "    print(\"No checkpoint found. Initializing from scratch.\")\n",
        "    # Initialize embeddings only if starting fresh\n",
        "    teacher_embed = teacher.model.encoder_frontend.embed.weight.data\n",
        "    student.embed.weight.data[:, :] = teacher_embed[:, :512]\n",
        "\n",
        "# 3. Data Loading\n",
        "# (Simplified for demo) - In production use the robust loader from previous cells\n",
        "print(\"Loading Dataset...\")\n",
        "try:\n",
        "    dataset = load_dataset(\"wikitext\", \"wikitext-2-v1\", split=\"train\")\n",
        "    texts = [x['text'].strip() for x in dataset if len(x['text']) > 50]\n",
        "    texts = texts[:20000] # Cap for demo speed\n",
        "    print(f\"Loaded {len(texts)} samples.\")\n",
        "except Exception as e:\n",
        "    print(f\"Data load failed: {e}\")\n",
        "    texts = [\"Test sentence one.\", \"Another test sentence.\"] * 100\n",
        "\n",
        "# 4. Run\n",
        "MAX_EPOCHS = 20\n",
        "PATIENCE = 3\n",
        "\n",
        "for epoch in range(start_epoch, MAX_EPOCHS):\n",
        "    print(f\"\\n=== Epoch {epoch+1}/{MAX_EPOCHS} ===\")\n",
        "    \n",
        "    def log_step(step, loss):\n",
        "        if step % 50 == 0:\n",
        "            print(f\"Step {step} | Loss: {loss:.4f} | Sim: {1-loss:.4f}\")\n",
        "            \n",
        "    avg_loss = trainer.train_epoch(texts, batch_size=32 if torch.cuda.device_count() > 1 else 16, step_callback=log_step)\n",
        "    print(f\"Epoch Complete. Avg Loss: {avg_loss:.4f}\")\n",
        "    \n",
        "    # Save Logic\n",
        "    if avg_loss < trainer.best_loss:\n",
        "        print(f\"New Best Model (Loss {avg_loss:.4f} < {trainer.best_loss:.4f}). Saving...\")\n",
        "        trainer.best_loss = avg_loss\n",
        "        trainer.save_checkpoint(str(CHECKPOINT_DIR / \"full_token_sonar_best.pt\"), epoch, avg_loss)\n",
        "        trainer.patience_counter = 0\n",
        "    else:\n",
        "        trainer.patience_counter += 1\n",
        "        print(f\"No improvement. Patience {trainer.patience_counter}/{PATIENCE}\")\n",
        "        \n",
        "    # Regular Checkpoint\n",
        "    trainer.save_checkpoint(str(CHECKPOINT_DIR / \"last_checkpoint.pt\"), epoch, avg_loss)\n",
        "    \n",
        "    # Early Stopping\n",
        "    if trainer.patience_counter >= PATIENCE:\n",
        "        print(\"Early stopping triggered.\")\n",
        "        break"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}